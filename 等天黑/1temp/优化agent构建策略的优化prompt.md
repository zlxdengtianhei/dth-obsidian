
我之前的要求是：
我现在需要你帮我完成一个非常复杂的任务，所以我需要你打开heartbeat，同时我希望你每次都要将我的原始prompt添加到任务检查的过程中，让他判断任务是否完成。


我希望你能够根据github中的opencode，oh-my-opencode，我在本机上已经安装了opencode cli，然后，我希望，你根据我下面的要求，完成任务，请你多审查任务进行的情况，以及我的模型api可用性。因为我当前的opencode中配置了可以使用claude opus，所以当你进行实际的设计时，请你都使用opencode，你来验收结果。并且请你根据模型可用性来决定是否先停下来，如果没有了claude 额度，你可以尝试使用你自己的claude继续进行设计，如果这个用不了使用gemini 3 pro（也是antigravity的），但是我需要你说明一下哪些任务是使用了哪些模型。如果都没发用了，可以使用kimi 2.5

总体要求：

下面的修改可能需要涉及到修改opencode的原始代码，为了这样的修改可以与opencode的更新兼容，我想请你找到一个最优的方案，让我能够保持自己的修改的情况下，也能够正常获得更新。请你告诉我你的方法，但是无论如何，如果你需要修改源码，请你先对你克隆当前的opencode代码库，然后修改完之后记录一下你都修改了哪些文件怎么修改了。

另外针对agent的设置，我需要你也思考与他们对应的hook或者command是否需要配套的进行设置来更好的完成任务。尤其是维护文档等等。

如果需要设计一个新的agent，我希望能够读取现有的agent的设置，然后根据已有的设计方式，结合这个agent的要求，设置风格一致，功能清晰的agent


按照弱时序，你可以逐步完成这些任务，但是也要进行审查，完成新的设置之后看看是否需要对之前的哪些部分修改：

---


首先维护一个模型列表，按照模型能力，给出一个分类表。根据订阅，可以灵活选择。首先搜索一下，集合大家对于市面上的所有模型擅长的项目的评价，以及模型提供商对于模型的定位，来决定模型能力，分为四类类，超强（根据价格应该是opus和gpt5.2pro？）强中弱，除了这三个分类，然后针对他们擅长的领域也进行一下细分，作为另一个纬度，这个表就是由这两个纬度决定的。然后，我希望你能够让opencode根据这个表，以及当前已有的订阅，来针对每个agent选择模型。因此agent在选择模型时，也是根据分类表提供的哪些能力，以及自己的system prompt，修改一下他们选择模型的代码，可以启用一个完善的回退机制，选择可用的模型。也要对模型的可用性检查，如果说限速了，可以实现自动的模型切换。

---

给omo（ohmyopencode）创建一个ecc（everything claude code）的refactor-cleaner

database reviewer

或者有其他的omo没有的，但是ecc中有的较好的agent可以添加进去，同时我记得omo中有一个评价很好的分支slim，如果确实这个分支能够更好的完成任务，请你修改当前的omo配置为这个分支的配置，如果采用了这个分支，主分支有什么更新无法使用，也请你手动添加一下。

然后请你看看是否有好用的hook，command可以添加，也请你添加一下。

---
然后有一个非常关键的任务，就是要创建一个进程文档的机制。我需要让每个agent在完成每个任务的时候，都需要维护一个进程文档，在这个文档中，就是需要agent说明，本次调用中，进行了哪些操作，完成了哪些修改，搜索了哪些内容（如果有的话），采用了什么样的方法，这个部分被要求在最后输出，用来作为总结部分输出。

这个todo和进程文档，我需要你采用类似的管理方式，如果todo不是一个确实存在的文档，可以考虑将这个进程文档作为一个独立的文档，与session id，或者是调用的次数相关。然后让普通的agent不需要查看这个文档直接随着任务进行更新文档就行，审查agent是需要必须要查看这个文档的。请你思考一个更优的解决方式，我希望这个文档尽可能的节省token，存储时一定是优秀的管理起来，放在当前project一个专门的文件夹中

---

在西西弗斯的prompt中说明无论如何一定要委派，在其他的agent中，也通过hook等方式，检查context，如果超过了75%，就需要根据todo，和进程文档，以及高强度压缩后的context，主要是包括了任务当前进行采用的方法，处理方式，当前已完成的任务以及剩余的任务，将它委派给一个新的agent继续完成。

默认采用junior 西西弗斯作为agent，如果启用ulw，采用西西弗斯。junior专为了普通任务的，所以采用中等模型，根据问题难度决定需要不需要委派，如果用户要求了委派就一定委派，同时这个委派的时候可以让他采用中等模型作为subagent进行。


优化西西弗斯的推球，如果缺少了东西，判断是否需要继续要求完成todo，如果确实缺少了必要的内容，那就要求用户提供而不是持续要求。

---


要编排agent的prompt中，明确的要求有一个确定的验收标准。并且说明这个验收标准是什么让用户判断。验收的时候，仔细考虑验收方式，如果任务具有一定的特性，尝试使用确定性的代码对这个共性进行验收。并且说明任务进程文档的存在，可以思考任务中的所有操作对象，或者是获取的资源，使用的方法，以及得到的结果，是否与一开始的用户prompt符合，

----

优化一下审查agent，这个agent非常的关键，请你看看当前omo中是否有这个agent，如果有，请你从我方才的任务文档的设置中，思考如何更好的让这个agent进行工作，让他能够确实完成任务的审查工作，这里面就是要专门根据用户的要求，以及任务进程文档，验收标准，来进行判断。这里面就需要批判性的对这些内容进行判断，如果说当前的任务完成的有问题，那就需要有重新修改的机制，这个里面可以更新todo，或者是创建新的todo，同时这个里面需要对subagent的机制进行仔细的设计，思考有问题之后，怎么处理。最好出现问题后，还是创建新的todo，然后委派新的agent完成，同时如果有出现问题的情况，也就意味着完成了新的结果还需要审查agent来进行审查。审查也可以类似进程文档管理一个审查文档，一个审查agent生成一个审查文档即可。

---
正如前面提到的，我需要你能够优化当前omo的agent委派机制，我需要你分配足够多的agent，来根据当前opencode中存在的agent，然后结合/Users/lexuanzhang/code/oc-test/Multi-Agent通信协议深度研究报告.md 这个报告，进行仔细的比对，设计，确定一个最优的委派协议，尤其是要仔细的处理编排，审查，修改后再审查等相关的逻辑。并且也要处理context 超过75%后的压缩，委派处理。另外采用在任务的最后，我需要你根据计划，实际实现文档，审查结果，总结出一个最终完整实现的文档。

另外还有一个较为关键的，甚至可以设置一个专门的agent，就是根据之前的没有完成的任务，来设置后续怎么继续任务，这时用户可能提供新的要求，结合进程文档，以及之前的plan，todo，完成后续任务的设置。

如果还有一些我没有考虑到的场景，结合我提供的深度研究报告中的实现，也进行设计。

同时也请你思考一下根据模型的prefill，等相关推理过程中的可能出现的操作，来判断一下委派的机制什么样可能会更好的在token最少的情况下完成任务？这个部分的优化可以后续再进行，但是请你思考一下。

---
同时我希望你搜索一下，当前的评价很好的skills，我记得还有专门用来找到skill的skill，然而无论mcp和skill，都是需要消耗context，我希望你创建一个agent可以专门用来根据实现计划，来确定可能需要的mcp和skill，因为计划中可能涉及了多个agent，对于不同的agent一定是不同的skill和mcp加载方案。这个加载的方案，也请你配合一下opencode的mcp和skill的使用机制，让他们更好的能够配合起来。

---
另外，我需要你根据当前设计好的agent，以及agent委派协议，再次思考一下，针对我的两个模式设置，一个是简单任务使用jonior 西西弗斯，默认不进行编排；一个是复杂任务，采用西西弗斯，以及默认编排。我需要你设计一个用户交互最小，最好再一次修改计划中，可以同时处理skill mcp的选择，以及计划的修改，采用足够方便的交互输入方式来修改（对于jonior，可以设置一个超时机制，如果进行了plan，用户超时没有修改，那就默认这个计划开始执行）。刚才可能没有提到，对agent的模型选择，我需要你统一之前说的根据模型能力，订阅（这个里面还需要考虑google antigravity auth插件，让我能够使用antigravity的额度），完善的回退机制来自动选择模型，也可以用户手动切换。只有编排模型需要超强模型，其他的西西弗斯，审查，可以采用强模型，更加简单的jonior 西西弗斯，找到skill，mcp的可以采用中级模型，最简单的阅读文件，搜索之类的任务，可以交给弱模型。

结合agent委派的机制，以及opencode的完成代码任务的方式，请你思考一下完成接受用户输入，进行编排，然后给出答案这个流程中是否可以优化用户体验的部分，对他们进行一下优化。尽量让人类的操作减少，但是需要修改的地方清晰，方便验收



---


找到信息时，考虑更优的信息源。另外专门维护一个可持续性的文档，作为优秀信源，这个可以是项目级保存，然后再长期保存的方式进行保存。
对于搜索的结果，评价标准就是找到git，reddit，x，等等社交媒体属性网站上讨论较多，stars，或者说点赞收藏较多的内容。针对没有这些属性的信息来源，考虑匹配度，思考信息真实性。另外如果有相关领域的论文，如果匹配度较好，也可以视为优秀的搜索结果。

---

针对目前的系统，根据已有的/Users/lexuanzhang/code/ohmyopencode/docs 中各个task子文件夹，以及integration文件夹，我希望你首先阅读所有的summary文件，在每个task文件夹中，然后阅读integration文件夹的文件。然后请你使用9个agent分别仔细查看当前的每个task实现，确定进度，对没有完成的部分进行实现。然后请你批判性的思考，如何对当前的系统进一步修改，请你分发任务给每个task，让他们完成修改，并且修改完了之后，请你交给另一个审计agent，注意是新的，然后审计一下是否还需要优化，注意一定要符合我的要求，不能为了优化而优化。


---
但是因为task1之没有正确完成，所以在你阅读的同时，直接开始使用一个子agent完成task1的实现。我希望你能够针对模型抽象层的部分进一步进行实现，我这个模型能力，以及擅长领域，主要是为了后续委派agent的时候，方便父agent根据任务，决定使用什么模型。所以可以保持固定好的agent的现有逻辑不变，用户自行选择模型就可以。你需要先安排agent去搜索了解模型的能力，然后设计这个文档。然后请你输出类似其他几个task的文档说明。


---


次外我希望你能够进一步创建可以用来构建子agent的agent，这个agent，请你结合目前已有的所有agent的设计方式，专门设计他为用来根据父agent设计子agent的功能。使用这些todo，进程文档，以及用户的原始prompt，等，同时根据模型能力文档和任务要求，选择模型，来构建子agent。
这个部分作为一个新的task，等完成这个task后，再进行审计流程，另外请你结合之前的agent交互时序逻辑，参考/Users/lexuanzhang/code/oc-test/Multi-Agent通信协议深度研究报告.md，以及openclaw的子agent交互逻辑，进一步优化这个agent之间的委派逻辑，然后设计这个专为构建子agent的agent。这个部分请你也直接使用一个审计agant来评价他的实现。注意不要被其他多余context影响，始终记得我的要求。

---
注意关于进程文档，我希望设计一个固定的格式，来对每次设计的llm进行了哪些操作，完成了哪些修改，搜索了哪些内容（如果有的话，并且注意是有用的信息），采用了什么样的方法，或者其他你认为在一次llm任务中重要的部分，将他们按照确定的格式记录下来，（然后可以维护另一个纬度的文档，就是针对某个文件，他历史的操作都有哪些，然后针对搜索的内容也可维护一个知识文档，记录搜索到的有用的信息注意这个另一个纬度文档的实现请你直接使用代码实现，匹配固定的那个格式）这个部分被要求在最后输出，用来作为总结部分输出，然后请你注意一定是精简，但是准确完整的内容，概括所有llm的操作。这个请你在对应的task阅读文档的之后，对这个部分的设计直接优化。
